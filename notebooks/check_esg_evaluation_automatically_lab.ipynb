{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Efficient ESG evaluation by NLP\n",
    "\n",
    "チェックリストに沿ったESG評価を自然言語処理で効率化するデモです。  \n",
    "チェックリストとは、ESGに関する質問のリストです。企業のレポートから適正な回答が得られた個数を数えることで評価します。質問は、Eであれば「気候変動リスクを監視する委員会があるか」「気候変動リスクと機会を特定するプロセスがあるか」などです。  \n",
    "自然言語処理を用い、質問に対する回答となる箇所を自動で抽出できれば評価業務の効率化ができます。\n",
    "\n",
    "![demo.PNG](./images/demo.PNG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "デモの手順は以下の通りです。\n",
    "\n",
    "1. Prepare: PDFファイル(統合報告書)からテキストを読み込みます。\n",
    "2. Preprocess: テキスト解析しやすいよう整形します。\n",
    "3. Retrieve: 質問に関連する箇所を抽出します。単語ベースとベクトルベースの2つを行います。\n",
    "4. (Optional) Answer: 関連する箇所から、質問の回答を抽出します。\n",
    "\n",
    "### Setup for running the notebook\n",
    "\n",
    "本Notebookを実行するには、必要なライブラリをインストールした環境が必要です。File > New > Terminalからターミナルを起動し、次のコマンドを実行してください。\n",
    "\n",
    "* `conda env create -f env-nlp.yml`\n",
    "* `conda activate env-nlp`\n",
    "\n",
    "メニューバーのKearnel > Change Kearnel...で`env-nlp`が選択できるようになっているはずです。Kearnelは特定のNotebookを動かすための専用環境のイメージです。もし選択できない場合、次のコマンドを実行しJupyterがKernelを認識できるようにしてください。\n",
    "\n",
    "```\n",
    "ipython kernel install --user --name=env-nlp\n",
    "```\n",
    "\n",
    "`ipython`がインストールされていない場合、次のコマンドでインストールしてください。\n",
    "\n",
    "* `conda install ipython`\n",
    "\n",
    "作成したKernelは他のNotebookでも利用できます。本ノートブックをベースに、いろんなテキストを分析してみましょう！\n",
    "\n",
    "## 1. Prepare\n",
    "\n",
    "PDFファイルからテキストを読み込みます。デモでは2019年のトヨタの統合報告書を使用しています。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "def set_root():\n",
    "    root = os.path.join(os.path.realpath(\".\"), \"../\")\n",
    "    if root not in sys.path:\n",
    "        sys.path.append(root)\n",
    "    return root\n",
    "\n",
    "ROOT_DIR = Path(set_root())\n",
    "DATA_DIR = ROOT_DIR / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDFファイルからのテキスト抽出は、事前に作成しておいた`PDFReader`クラスを使用します。内部的には[`pdfminer.six`](https://github.com/pdfminer/pdfminer.six)を使用しています。  \n",
    "実装に興味がある方は[ソースコード](https://github.com/icoxfog417/esg-evaluation-by-nlp/blob/master/esg_nlp/data/pdf_reader.py)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from esg_nlp.data.pdf_reader import PDFReader\n",
    "reader = PDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / f\"raw/2019_001_annual_en.pdf\"\n",
    "df = reader.read_to_frame(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "PDF読み込み結果を表示します。\n",
    "\n",
    "* page: ページ番号\n",
    "* order: ページ内のセクション番号(登場順にカウント)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>order</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Annual Report \\nAnnual Report 2019\\nFiscal yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Table of Contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1 \\nTable of Contents\\n2 \\nMessage from the Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page  order                                            content\n",
       "0     0      0                                             Page 1\n",
       "1     0      1  Annual Report \\nAnnual Report 2019\\nFiscal yea...\n",
       "2     1      0                                             Page 1\n",
       "3     1      1                                  Table of Contents\n",
       "4     1      2  1 \\nTable of Contents\\n2 \\nMessage from the Pr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess\n",
    "\n",
    "PDF読み込み結果は様々なノイズを含んでいるので、前処理を行います。前処理として文字をすべて小文字にするなどします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# 小文字に統一など\n",
    "preprocessed = reader.preprocess_frame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "`Page 1`など、タイトルのみで文を含んでいないセクションを除外します。文の判定は、ピリオドや疑問符の有無で判定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>order</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>the annual report 2019 is intended to communic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>about the pdfthis file is an interactive pdf a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>icons found in each section link to related pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>toyota’s reports and publications*  toyota als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reforming our company to become a “mobility co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page  order                                            content\n",
       "4      1      3  the annual report 2019 is intended to communic...\n",
       "5      1      4  about the pdfthis file is an interactive pdf a...\n",
       "9      1      8  icons found in each section link to related pa...\n",
       "16     1     15  toyota’s reports and publications*  toyota als...\n",
       "23     2      2  reforming our company to become a “mobility co..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文を含んでいないセクションを削除\n",
    "has_sentence = re.compile(\"(•)?\\s?[A-Za-z](\\s)?(\\.|;)\")\n",
    "preprocessed = preprocessed[preprocessed[\"content\"].apply(lambda s: re.search(has_sentence, s) is not None)]\n",
    "\n",
    "preprocessed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows are decreased from 747 to 189\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows are decreased from {len(df)} to {len(preprocessed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>order</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>the annual report 2019 is intended to communic...</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>about the pdfthis file is an interactive pdf a...</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>icons found in each section link to related pa...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>toyota’s reports and publications*  toyota als...</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reforming our company to become a “mobility co...</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page  order                                            content  length\n",
       "4      1      3  the annual report 2019 is intended to communic...     348\n",
       "5      1      4  about the pdfthis file is an interactive pdf a...     208\n",
       "9      1      8  icons found in each section link to related pa...     155\n",
       "16     1     15  toyota’s reports and publications*  toyota als...     569\n",
       "23     2      2  reforming our company to become a “mobility co...     367"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = preprocessed.assign(length=preprocessed[\"content\"].apply(lambda s: len(s)))\n",
    "preprocessed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve\n",
    "\n",
    "チェックリストの質問に関係しているセクションを抽出します。単語ベースで行う手法と、ベクトルベースで行う手法を紹介します。\n",
    "\n",
    "質問文は[CDP(Carbon Disclosue Project)](https://www.kaggle.com/c/cdp-unlocking-climate-solutions/overview)の質問を使用しました。CDPはKaggleでコンペティションを実施したことがあり、一部のデータを参照することが可能です(本当は購入しないと参照できません💦)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDPのC2.1の質問\n",
    "question = \"Does your organization have a process for identifying, assessing, and responding to climate-related risks and opportunities ?\"\n",
    "question = question.lower()\n",
    "language = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Word base retrieval\n",
    "\n",
    "単純に質問文に含まれている単語を含むセクションを抽出します。文を単語に区切るため[spaCy](https://spacy.io/)を利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/esg-nlp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import get_lang_class\n",
    "\n",
    "\n",
    "class Parser():\n",
    "\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.parser = get_lang_class(self.lang)()\n",
    "    \n",
    "    def parse(self, text):\n",
    "        return self.parser(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "質問から単語を抽出します。この時、ストップワードと呼ばれる一般的すぎる単語は除外します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organization',\n",
       " 'process',\n",
       " 'identifying',\n",
       " 'assessing',\n",
       " 'responding',\n",
       " 'climate',\n",
       " 'related',\n",
       " 'risks',\n",
       " 'opportunities']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = Parser(language)\n",
    "question_words = [str(t).strip() for t in parser.parse(question) if not t.is_stop and not re.match(\"\\'|\\.|\\?|\\/|\\,|\\-\", t.text)]\n",
    "question_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セクションごとにキーワードが含まれる数をカウントします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_keyword_match(parser, keywords, text):\n",
    "    tokens = parser.parse(text)\n",
    "    count = 0\n",
    "    for t in tokens:\n",
    "        if str(t).lower().strip() in keywords:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "counted = preprocessed.assign(\n",
    "            keyword_match=preprocessed[\"content\"].apply(\n",
    "            lambda s: count_keyword_match(parser, question_words, s))\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>order</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "      <th>keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>organization and structuretoyota has appointed...</td>\n",
       "      <td>1697</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>making over the decades has been made possible...</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>initiatives related to persons with disabiliti...</td>\n",
       "      <td>3156</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>sustainability meetingreceives reports and del...</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>royalty-free licenses to 23,740 patents relate...</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     page  order                                            content  length  \\\n",
       "424    37      3  organization and structuretoyota has appointed...    1697   \n",
       "392    34      4  making over the decades has been made possible...    2022   \n",
       "418    36      5  initiatives related to persons with disabiliti...    3156   \n",
       "277    25      7  sustainability meetingreceives reports and del...     264   \n",
       "136    12     13  royalty-free licenses to 23,740 patents relate...     302   \n",
       "\n",
       "     keyword_match  \n",
       "424              9  \n",
       "392              4  \n",
       "418              3  \n",
       "277              2  \n",
       "136              2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched = counted[counted[\"keyword_match\"] > 0]\n",
    "matched.sort_values(by=[\"keyword_match\"], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "キーワードの一致数が多い、つまり重要なセクションにフォーカスして調査をすることが可能になります。\n",
    "\n",
    "## 3.2 Vector base retrieval\n",
    "\n",
    "キーワードだけでなく、文章の意味を考慮したセクションの抽出を行います。文章をベクトルとして表現し、ベクトル間の距離で意味の近さを判定します。 \n",
    "文章をベクトル化するために、[Googleの検索でも使用されたBERTという手法](https://blog.google/products/search/search-language-understanding-bert/)を使用します。[Hugging Face](https://huggingface.co/)というライブラリで比較的簡単に扱うことができます。\n",
    "\n",
    "セクションは非常に長いので、文単位に分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>section_order</th>\n",
       "      <th>sentence_order</th>\n",
       "      <th>sentence</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>the annual report 2019 is intended to communic...</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>more detailed information on toyota’s esg-rel...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>(published december 2019)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>about the pdfthis file is an interactive pdf a...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>jump to the beginning of each of the report’s ...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page  section_order  sentence_order  \\\n",
       "0     1              3               0   \n",
       "1     1              3               1   \n",
       "2     1              3               2   \n",
       "3     1              4               0   \n",
       "4     1              4               1   \n",
       "\n",
       "                                            sentence  length  \n",
       "0  the annual report 2019 is intended to communic...     209  \n",
       "1   more detailed information on toyota’s esg-rel...     112  \n",
       "2                          (published december 2019)      25  \n",
       "3  about the pdfthis file is an interactive pdf a...     103  \n",
       "4  jump to the beginning of each of the report’s ...     104  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for i, row in preprocessed.iterrows():\n",
    "    c = row[\"content\"]\n",
    "    for j, s in enumerate(c.replace(\"•\", \".\").replace(\";\", \".\").split(\".\")):\n",
    "        sentences.append({\n",
    "            \"page\": row[\"page\"],\n",
    "            \"section_order\": row[\"order\"],\n",
    "            \"sentence_order\": j,\n",
    "            \"sentence\": s,\n",
    "            \"length\": len(s)\n",
    "        })\n",
    "\n",
    "sentences = pd.DataFrame(sentences)\n",
    "sentences.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1717"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTのモデルを使用し、文をベクトル表現に変換します。事前に作成しておいた`encode`関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esg_nlp.model.encoder import encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepair the tokenizer...\n",
      "Set the pipeline.\n",
      "Inference start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:36<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "embeddings = encode(model_name, sentences[\"sentence\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1717, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1717個の文それぞれに対し、768次元のベクトルが得られました。質問文もベクトルにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepair the tokenizer...\n",
      "Set the pipeline.\n",
      "Inference start.\n"
     ]
    }
   ],
   "source": [
    "query = encode(model_name, question)\n",
    "query = np.reshape(query, (1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "質問文のベクトルと、各文のベクトルとの距離を算出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>section_order</th>\n",
       "      <th>sentence_order</th>\n",
       "      <th>sentence</th>\n",
       "      <th>length</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>sustainability meetingreceives reports and del...</td>\n",
       "      <td>263</td>\n",
       "      <td>0.900027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>we are also promoting activities in social, c...</td>\n",
       "      <td>225</td>\n",
       "      <td>0.881857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>when advancing initiatives in safety and heal...</td>\n",
       "      <td>155</td>\n",
       "      <td>0.880402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>building positive relation-ships with all sta...</td>\n",
       "      <td>242</td>\n",
       "      <td>0.872589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>currently, we have identified three areas—fre...</td>\n",
       "      <td>257</td>\n",
       "      <td>0.871311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.165867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.165867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.165867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.165867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.165867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1717 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      page  section_order  sentence_order  \\\n",
       "920     25              7               0   \n",
       "1589    40              4               5   \n",
       "1384    35              3               6   \n",
       "985     27              5               1   \n",
       "1336    34              4               7   \n",
       "...    ...            ...             ...   \n",
       "948     26              5               8   \n",
       "950     26              5              10   \n",
       "956     26             11               3   \n",
       "957     26             11               4   \n",
       "671     19              2               3   \n",
       "\n",
       "                                               sentence  length  distance  \n",
       "920   sustainability meetingreceives reports and del...     263  0.900027  \n",
       "1589   we are also promoting activities in social, c...     225  0.881857  \n",
       "1384   when advancing initiatives in safety and heal...     155  0.880402  \n",
       "985    building positive relation-ships with all sta...     242  0.872589  \n",
       "1336   currently, we have identified three areas—fre...     257  0.871311  \n",
       "...                                                 ...     ...       ...  \n",
       "948                                                           0  0.165867  \n",
       "950                                                           0  0.165867  \n",
       "956                                                           0  0.165867  \n",
       "957                                                           0  0.165867  \n",
       "671                                                           0  0.165867  \n",
       "\n",
       "[1717 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "distance = cosine_similarity(query, embeddings)\n",
    "measured = sentences.assign(\n",
    "            distance=distance.flatten())\n",
    "\n",
    "measured.sort_values(\"distance\", ascending=False, inplace=True)\n",
    "measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "質問は気候変動に関するリスクや機会を対策するプロセスを問うものです。その観点では、`manage-ment issues`や`proactively advance initiatives`に関する記述が取れているのは意味を組んでいる印象です。ただ、気候変動に関する文書かというと読み取れないところもあるので、特別に重視したい単語(今回は\"climate\")がある場合は、いったんキーワードであたりをつけてから使用したほうが有効に見えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.(Optional) Answer:\n",
    "\n",
    "質問回答を学習させたモデルを利用して、直接的に回答を抽出する手法もあります。キーワードで絞り込んだデータから回答を抽出してみましょう。\n",
    "\n",
    "回答箇所の抽出には、自然言語処理の質問回答の手法を使用します。Wikipediaをベースにした質問回答のデータセット([SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)と呼ばれる)で事前に学習したモデルをお持ちいます。本来はESGに関する質問と回答のデータセットで転移学習したほうが良いですが、今回は学習せずに用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esg_nlp.model.question_answer import answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1つはキーワードにマッチしているセクションを対象にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_match = 1\n",
    "question_section_pair = matched[matched[\"keyword_match\"] >= minimum_match][\"content\"].apply(lambda s: (question, s)).tolist()\n",
    "len(question_section_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model...\n",
      "Prepair the tokenizer...\n",
      "Set the pipeline.\n",
      "Answer start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/48 [00:00<00:04, 10.08it/s]/home/studio-lab-user/.conda/envs/esg-nlp/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/studio-lab-user/.conda/envs/esg-nlp/lib/python3.8/site-packages/transformers/pipelines/question_answering.py:295: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "100%|██████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092548</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134468</td>\n",
       "      <td>123</td>\n",
       "      <td>154</td>\n",
       "      <td>requires an internet connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012953</td>\n",
       "      <td>173</td>\n",
       "      <td>251</td>\n",
       "      <td>developing people message from the cfo capital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>402</td>\n",
       "      <td>459</td>\n",
       "      <td>joint venture related to the town development ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>992</td>\n",
       "      <td>996</td>\n",
       "      <td>tnga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                                             answer\n",
       "0  0.092548     66   72                                             toyota\n",
       "1  0.134468    123  154                    requires an internet connection\n",
       "2  0.012953    173  251  developing people message from the cfo capital...\n",
       "3  0.000197    402  459  joint venture related to the town development ...\n",
       "4  0.000305    992  996                                               tnga"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = answer(\"distilbert-base-uncased-distilled-squad\", question_section_pair)\n",
    "pd.DataFrame(answers).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`score`が低く、回答があまり正確に取れていないようです。ESGに関する質問は一言で回答できるものではないので、そのまま使うのは難しいかもしれません。\n",
    "\n",
    "デモは以上です。実際人間が行った時の評価と比べてどうか、ぜひ検証してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg-nlp:Python",
   "language": "python",
   "name": "conda-env-esg-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
